\section{Экспериментальная оценка и анализ результатов}

После разработки и реализации инструментария был проведен цикл вычислительных экспериментов для количественной оценки эффективности предложенного подхода и сравнения результатов, достигаемых различными моделями искусственного интеллекта. Экспериментальная установка включала описанный инструментарий, тестовую программу на Go и три нейронные сети на основе архитектуры Трансформер: \texttt{gemini-2.5-flash-preview-04-17}, \texttt{deepseek-chat-v3-0324} и \texttt{gemini-2.0-flash}, доступ к которым осуществлялся через API. Для каждой модели и целевой техники метаморфизма (вставка "мертвого" кода или модификация потока управления) использовался специализированный промпт, содержащий подробное объяснение техники метаморфизма, пример использования, основные замечания по генерации кода на Go и исходный код, который подлежит модификации. Проверка функциональной эквивалентности $FE$ проводилась отдельно для каждого сгенерированного варианта. В данном разделе анализируются показатели $FE$ и метрики обфускации ($LOC_{fin}$, $CC_{fin}$, $CogC_{fin}$) для успешно скомпилированных модификаций.

Сводные усредненные данные экспериментов представлены в Таблице~\ref{tab:exp_results_article}.

\begin{table*}[h!]
\centering
\captionsetup{justification=centering} % Центрирование подписи таблицы
\caption{Медианные значения метрик для различных моделей нейронных сетей и техник метаморфизма}
\label{tab:exp_results}
% Определяем таблицу шириной в \textwidth
% X столбец - растягиваемый с переносом текста, выравнивание по левому краю
% >{\RaggedRight} используется для лучшего вида левого выравнивания в X
% c - центрированный столбец
% @{} убирает пробелы по краям таблицы
\begin{tabularx}{12cm}{@{} >{\RaggedRight}X >{\RaggedRight}Xcccc}
\toprule
% Используем \multicolumn{1}{c}{...} если нужен перенос в заголовке X столбца
\textbf{Модель} & \textbf{Техника} & \textbf{$FE$ (\%)} & \textbf{$LOC_{fin}$ (\%)} & \textbf{$CC_{fin}$ (\%)} & \textbf{$CogC_{fin}$ (\%)} \\
\midrule
% Dead Code Results
\txtexttt{gemini-2.5-flash-preview} & Вставка "мертвого"\, кода & 93 & 612 & 640 & 905 \\
\vspace{5cm}
 & Модификация потока & 100 & 297 & 167 & 1121 \\
\midrule
\txtexttt{deepseek-chat-v3} & Вставка "мертвого"\, кода & 92 & 161 & 284 & 417 \\
 & Модификация потока & 43 & 89 & 90 & 321 \\
\midrule
\txtexttt{gemini-2.0-flash} & Вставка "мертвого" кода & 100 & 245 & 443 & 619 \\
 & Модификация потока & 53 & 211 & 72 & 702 \\
\bottomrule
\end{tabularx}
%\textit{Примечание: Данные FE округлены до целых для наглядности.} % Можно добавить примечание, если нужно
\end{table*}

Анализ результатов позволяет сравнить влияние техник метаморфизма и эффективность различных моделей LLM. Техника вставки "мертвого"\, кода стабильно обеспечивает высокую функциональную эквивалентность (92-100\%) при значительном увеличении объема кода и существенном росте метрик сложности. Это указывает на способность LLM генерировать семантически нейтральный, но объемный и структурно сложный дополнительный код.

Модификация потока управления демонстрирует иные тенденции. Прирост объема кода значительно ниже, что ожидаемо. Ключевым эффектом является резкое увеличение когнитивной сложности ($CogC_{fin}$ до 1121\%), подтверждая гипотезу о том, что данная техника наиболее эффективно затрудняет понимание кода человеком \cite{SonarSourceCogC}. Однако сохранение функциональной эквивалентности ($FE$) при этой технике оказалось серьезной проблемой для моделей \texttt{deepseek-chat-v3-0324} (43\%) и \texttt{gemini-2.0-flash} (53\%). Лишь модель \texttt{gemini-2.5-flash-preview-04-17} смогла обеспечить 100\% $FE$ при модификации потока, показав при этом максимальный прирост $CogC_{fin}$. Низкий прирост цикломатической сложности у некоторых моделей при модификации потока может свидетельствовать о генерации конструкций, запутанных для человека, но не обязательно увеличивающих число путей выполнения так же сильно, как вставка сложного "мертвого"\, кода.

Сравнение моделей LLM выявило различные профили эффективности. Модель \texttt{gemini-2.5-flash-preview-04-17} проявила себя как наиболее эффективная, обеспечивая максимальные показатели усложнения, особенно при вставке кода, и являясь единственной моделью, сохранившей 100\% $FE$ при модификации потока. Модель \texttt{deepseek-chat-v3-0324} показала наиболее "консервативные" результаты, с наименьшим усложнением и крайне низкой $FE$ при модификации потока. Модель \texttt{gemini-2.0-flash} продемонстрировала компромиссный результат: идеальная $FE$ при вставке кода с хорошим усложнением, но низкая $FE$ при модификации потока, несмотря на высокий прирост $CogC_{fin}$. Выбор оптимальной модели зависит от приоритетов: максимальная обфускация или гарантированная функциональность.

В целом, эксперименты подтвердили эффективность автоматизированного метаморфизма с использованием LLM для кода Go. Достигнут значительный прирост метрик сложности, что демонстрирует потенциал подхода для усложнения анализа. Однако выявлены ключевые проблемы нестабильность сохранения функциональной эквивалентности, особенно при модификации потока управления, что подчеркивает необходимость тщательного тестирования. Текущие метрики дают лишь косвенную оценку стойкости к реверс-инжинирингу, и требуется разработка более точных методов оценки. Зависимость от качества промптов и вариативность ответов LLM также требуют дальнейшего изучения.